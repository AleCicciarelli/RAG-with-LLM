{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "\n",
    "\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "  os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")\n",
    "\n",
    "#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 token hugging-face\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"/home/ciccia/.cache/huggingface/hub/models--sentence-transformers--all-mpnet-base-v2/snapshots/12e86a3c702fc3c50205a8db88f0ec7c0b6b94a0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INDEXING PART\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='4: Elena, Gonzalez, with ID 5, is a Female student born in 1999-09-05, with Spanish nationality and the enrollment in the university was done in 2022-02-14.' metadata={'source': './students.csv', 'row': 4}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Caricare il CSV\n",
    "loader = CSVLoader(file_path=\"./students.csv\")\n",
    "data = loader.load()\n",
    "\n",
    "# Trasformare i dati in frasi strutturate\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=f\"{doc.metadata['row']}: {doc.page_content.splitlines()[1].split(': ')[1]}, {doc.page_content.splitlines()[2].split(': ')[1]}, \"\n",
    "                     f\"with ID {doc.page_content.splitlines()[0].split(': ')[1]}, is a {doc.page_content.splitlines()[5].split(': ')[1]} student \"\n",
    "                     f\"born in {doc.page_content.splitlines()[3].split(': ')[1]}, with {doc.page_content.splitlines()[4].split(': ')[1]} nationality \"\n",
    "                     f\"and the enrollment in the university was done in {doc.page_content.splitlines()[6].split(': ')[1]}.\",\n",
    "        metadata=doc.metadata\n",
    "    )\n",
    "    for doc in data\n",
    "]\n",
    "\n",
    "# Stampare il primo documento per verifica\n",
    "print(documents[4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '3e03f8c7-e485-430a-8e83-498766c318d2', 1: 'a24d840f-6c5e-4a30-929c-68ad29990eed', 2: '86485dce-b1f3-410a-b2d7-33c0f663c4bf', 3: '2f8911e7-e830-4f57-81b5-40a8dc14aa31', 4: '9abca1ad-d710-4ea0-97b6-79851f1d8622'}\n",
      "FAISS vector store created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Crea direttamente il vector store e lascia che LangChain calcoli gli embeddings\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents=documents,  # I documenti da indicizzare\n",
    "    embedding=embedding_model  # LangChain calcola gli embeddings automaticamente\n",
    ")\n",
    "print(vector_store.index_to_docstore_id)\n",
    "print(\"FAISS vector store created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract sentences from csv data to make data more understandable for LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RETRIEVAL AND GENERATION PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langchain import hub\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"], k = 5)\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control flow: Finally, we compile our application into a single graph object. In this case, we are just connecting the retrieval and generation steps into a single sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giulia Rossi enrolled in the university on 2022-09-01. This information was obtained from the provided context, specifically from the student's record with ID 1.\n",
      "There are 5 students enrolled in total.\n",
      "Based on the provided context, the year with the large number of students enrolled is 2022, with three students (Giulia, Marco, and Elena) enrolling in the university that year.\n",
      "Elena Gonzales comes from Spain, as indicated by her Spanish nationality.\n",
      "The youngest student is Sophie, Durand, with a birthdate of 2000-07-30.\n"
     ]
    }
   ],
   "source": [
    "#Test RAG application\n",
    "question = \"When did Giulia Rossi enroll and how did you get the information?\"\n",
    "result = graph.invoke({\"question\": question})\n",
    "print(result[\"answer\"])\n",
    "#Test RAG application\n",
    "question = \"How many students are enrolled?\"\n",
    "result = graph.invoke({\"question\": question})\n",
    "print(result[\"answer\"])\n",
    "#question which requires SQL rules --> LLM answers : \"I don't know. The given context does not provide information about the number of students enrolled in a specific year.\"\n",
    "question = \"In which year the large number of students enrolled? Try to count the number of students enrolled per year\"\n",
    "result = graph.invoke({\"question\": question})\n",
    "print(result[\"answer\"])\n",
    "\n",
    "question = \"Where Elena Gonzales comes from?\"\n",
    "result = graph.invoke({\"question\": question})\n",
    "print(result[\"answer\"])\n",
    "\n",
    "question = \"Which is the youngest student?\"\n",
    "result = graph.invoke({\"question\": question})\n",
    "print(result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
