{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "\n",
    "\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "  os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")\n",
    "\n",
    "#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 token hugging-face\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"/home/ciccia/.cache/huggingface/hub/models--sentence-transformers--all-mpnet-base-v2/snapshots/12e86a3c702fc3c50205a8db88f0ec7c0b6b94a0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INDEXING PART\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='4: Elena, Gonzalez, with ID 5, is a Female student born in 1999-09-05, with Spanish nationality and the enrollment in the university was done in 2022-02-14.' metadata={'source': './students.csv', 'row': 4}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Caricare il CSV\n",
    "loader = CSVLoader(file_path=\"./students.csv\")\n",
    "data = loader.load()\n",
    "\n",
    "# Trasformare i dati in frasi strutturate\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=f\"{doc.metadata['row']}: {doc.page_content.splitlines()[1].split(': ')[1]}, {doc.page_content.splitlines()[2].split(': ')[1]}, \"\n",
    "                     f\"with ID {doc.page_content.splitlines()[0].split(': ')[1]}, is a {doc.page_content.splitlines()[5].split(': ')[1]} student \"\n",
    "                     f\"born in {doc.page_content.splitlines()[3].split(': ')[1]}, with {doc.page_content.splitlines()[4].split(': ')[1]} nationality \"\n",
    "                     f\"and the enrollment in the university was done in {doc.page_content.splitlines()[6].split(': ')[1]}.\",\n",
    "        metadata=doc.metadata\n",
    "    )\n",
    "    for doc in data\n",
    "]\n",
    "\n",
    "# Stampare il primo documento per verifica\n",
    "print(documents[4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'fd7d06bd-e75a-4b45-91fd-975c349fc0cd', 1: '24c53d50-0242-4d8e-8a88-a7245e785aa1', 2: '480dea62-a4b0-47bb-b659-313fabfad307', 3: 'b5065f14-5101-45a0-8217-d918387da7d6', 4: '7a247dca-01bb-44a2-975c-9cb616037b03'}\n",
      "FAISS vector store created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Crea direttamente il vector store e lascia che LangChain calcoli gli embeddings\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents=data,  # I documenti da indicizzare\n",
    "    embedding=embedding_model  # LangChain calcola gli embeddings automaticamente\n",
    ")\n",
    "print(vector_store.index_to_docstore_id)\n",
    "print(\"FAISS vector store created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract sentences from csv data to make data more understandable for LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RETRIEVAL AND GENERATION PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langchain import hub\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"], k = 5)\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control flow: Finally, we compile our application into a single graph object. In this case, we are just connecting the retrieval and generation steps into a single sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giulia Rossi enrolled on 2022-09-01. I got this information from the provided context, specifically from the \"enrollment_date\" field for Giulia Rossi's record.\n",
      "There are 5 students enrolled.\n",
      "According to the retrieved context, a large number of students enrolled in 2022. Specifically, three students (Marco, Giulia, and Elena) enrolled in that year.\n",
      "Elena Gonzalez is from Spain, as indicated by her nationality in the context.\n",
      "Based on the provided context, Sophie Durand, born on 2000-07-30, is the youngest student.\n"
     ]
    }
   ],
   "source": [
    "#Test RAG application\n",
    "question = \"When did Giulia Rossi enroll and how did you get the information?\"\n",
    "result = graph.invoke({\"question\": question})\n",
    "print(result[\"answer\"])\n",
    "#Test RAG application\n",
    "question = \"How many students are enrolled?\"\n",
    "result = graph.invoke({\"question\": question})\n",
    "print(result[\"answer\"])\n",
    "#question which requires SQL rules --> LLM answers : \"I don't know. The given context does not provide information about the number of students enrolled in a specific year.\"\n",
    "question = \"In which year the large number of students enrolled? Try to count the number of students enrolled per year\"\n",
    "result = graph.invoke({\"question\": question})\n",
    "print(result[\"answer\"])\n",
    "\n",
    "question = \"Where Elena Gonzales comes from?\"\n",
    "result = graph.invoke({\"question\": question})\n",
    "print(result[\"answer\"])\n",
    "\n",
    "question = \"Which is the youngest student?\"\n",
    "result = graph.invoke({\"question\": question})\n",
    "print(result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
